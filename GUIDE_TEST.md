# ğŸŒ¤ï¸ Guide de Test - Collecte et Publication Kafka

## ğŸ“‹ Ce que font vos scripts

### 1. **Collecte des donnÃ©es via API Open Meteo**
- âœ… Collecte mÃ©tÃ©o pour 5 villes europÃ©ennes
- âœ… DonnÃ©es complÃ¨tes : actuelles, horaires, quotidiennes
- âœ… Enrichissement avec mÃ©tadonnÃ©es et qualitÃ© des donnÃ©es

### 2. **Publication des Ã©vÃ©nements dans Kafka**
- âœ… Envoi vers le topic `weather-data`
- âœ… Partitioning par ville (clÃ© = city_id)
- âœ… SÃ©rialisation JSON automatique
- âœ… Confirmation de rÃ©ception

## ğŸš€ Instructions de Test

### Ã‰tape 1 : DÃ©marrer les services Docker
```powershell
# DÃ©marrer tous les services
.\scripts\manage-services.ps1 start

# Ou manuellement
docker-compose up -d
```

### Ã‰tape 2 : VÃ©rifier que Kafka fonctionne
```powershell
# Script de vÃ©rification complet
python src/ingestion/kafka_checker.py
```

**Ce script va :**
- âœ… Tester la connexion Kafka
- âœ… CrÃ©er les topics nÃ©cessaires
- âœ… Tester producer/consumer
- âœ… Afficher un rapport de santÃ©

### Ã‰tape 3 : Lancer la collecte et publication
```powershell
# Collecteur principal (collecte + publication Kafka)
python src/ingestion/weather_collector.py
```

**Ce script va :**
- ğŸŒ Collecter les donnÃ©es Open Meteo toutes les 2 minutes
- ğŸ“¤ Publier chaque message dans Kafka
- ğŸ“Š Afficher les statistiques en temps rÃ©el
- ğŸ”„ Tourner en continu (Ctrl+C pour arrÃªter)

### Ã‰tape 4 : VÃ©rifier la rÃ©ception des donnÃ©es
```powershell
# Dans un autre terminal - Consumer de test
python src/ingestion/consumer_with_filters.py
```

## ğŸ“Š Monitoring

### VÃ©rifier l'Ã©tat des services
```powershell
.\scripts\manage-services.ps1 status
```

### Voir les logs
```powershell
.\scripts\manage-services.ps1 logs
```

### Interfaces Web disponibles
- **Spark Master UI** : http://localhost:8080
- **Spark Worker UI** : http://localhost:8081

## ğŸ¯ Structure des Messages Kafka

Chaque message publiÃ© contient :

```json
{
  "message_id": "paris_1727123456",
  "timestamp": "2025-09-24T10:30:00Z",
  "city_info": {
    "id": "paris",
    "name": "Paris",
    "lat": 48.8566,
    "lon": 2.3522,
    "country": "France"
  },
  "weather_data": {
    "current_weather": {...},
    "hourly": {...},
    "daily": {...}
  },
  "data_quality": {
    "api_response_time": 0.234,
    "data_size_bytes": 15234,
    "has_current": true,
    "has_hourly": true,
    "has_daily": true
  },
  "metadata": {
    "source": "open-meteo-api",
    "collector_version": "1.0",
    "collection_method": "http_api"
  }
}
```

## ğŸ”§ Configuration

### Topics Kafka crÃ©Ã©s automatiquement
- `weather-data` (3 partitions) - DonnÃ©es mÃ©tÃ©o principales
- `weather-alerts` (2 partitions) - Alertes mÃ©tÃ©o

### Villes surveillÃ©es
- Paris, France
- London, UK  
- Berlin, Germany
- Madrid, Spain
- Rome, Italy

### ParamÃ¨tres collectÃ©s
- **Actuels** : TempÃ©rature, vent, conditions
- **Horaires** : TempÃ©rature, humiditÃ©, prÃ©cipitations, pression, vent
- **Quotidiens** : Min/max tempÃ©ratures, prÃ©cipitations, vent max

## ğŸ› ï¸ DÃ©pannage

### Kafka ne dÃ©marre pas
```powershell
# RedÃ©marrer les services
.\scripts\manage-services.ps1 restart

# VÃ©rifier les logs
docker-compose logs kafka
```

### Erreur de connexion API
- VÃ©rifiez votre connexion internet
- L'API Open Meteo est gratuite et sans clÃ©

### Producer ne se connecte pas
- VÃ©rifiez que Kafka est dÃ©marrÃ© : `docker-compose ps`
- Testez la connectivitÃ© : `python src/ingestion/kafka_checker.py`

## ğŸ“ˆ RÃ©sultats Attendus

AprÃ¨s quelques minutes, vous devriez voir :
- âœ… **5 villes** collectÃ©es par cycle
- âœ… **Messages Kafka** publiÃ©s avec succÃ¨s
- âœ… **Statistiques** en temps rÃ©el
- âœ… **DonnÃ©es enrichies** avec mÃ©tadonnÃ©es

Le systÃ¨me collecte et publie automatiquement toutes les 2 minutes ! ğŸ‰